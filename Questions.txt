how about here
https://stackoverflow.com/questions/2307283/what-does-olog-n-mean-exactlyIn
In logarithm graph time curve decelerates as n increases.

Logarithm is essentially the inverse of exponentiation.

Now, if you can prove, that at every iteration of your algorithm you cut off a fraction of this space,
 that is no less than some limit, this means that your algorithm is running in O(logN) time.

O(log n) running times are very common in any sort of divide-and-conquer application, because you are (ideally) cutting the work in half every time.
Then why not log(N/2)


What is the complexity of recursive left shift operator
=================================================================
Added this line from denSub branch
